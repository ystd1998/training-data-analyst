{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network on pixel neighborhoods\n",
    "\n",
    "This notebook reads the pixel-neighborhood data written out by the Dataflow program of [1_explore.ipynb](./1_explore.ipynb) and trains a simple convnet model on Cloud ML Engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 'Y' | gcloud components update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install --upgrade tensorflow cloudml-hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PWD}/ltgpred/\n",
    "OUTDIR=${PWD}/cnn_trained\n",
    "DATADIR=${PWD}/preproc/tfrecord\n",
    "rm -rf $OUTDIR\n",
    "python -m trainer.train_cnn \\\n",
    "    --train_steps=10 --num_eval_records=512 --train_batch_size=16 --num_cores=1 --nlayers=5 --arch=convnet \\\n",
    "    --job-dir=$OUTDIR --train_data_path=${DATADIR}/train* --eval_data_path=${DATADIR}/eval*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "saved_model_cli show --all --dir $(ls -d -1 /content/blogs/lightning/cnn_trained/export/exporter/* | tail -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export CLOUDSDK_PYTHON=$(which python3)\n",
    "OUTDIR=${PWD}/cnn_trained\n",
    "DATADIR=${PWD}/preproc/tfrecord\n",
    "rm -rf $OUTDIR\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.train_cnn --package-path=${PWD}/ltgpred/trainer \\\n",
    "    -- \\\n",
    "    --train_steps=10 --num_eval_records=512 --train_batch_size=16 --num_cores=1 --nlayers=5 \\\n",
    "    --job-dir=$OUTDIR --train_data_path=${DATADIR}/train* --eval_data_path=${DATADIR}/eval*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training lighting prediction model on CMLE using GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_model_m_gpu is a machine with 4 K-80 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile largemachine.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: complex_model_m_p100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#DATADIR=gs://$BUCKET/lightning/preproc/tfrecord\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "\n",
    "#for ARCH in feateng convnet dnn resnet; do\n",
    "for ARCH in convnet; do\n",
    "  JOBNAME=ltgpred_${ARCH}_$(date -u +%y%m%d_%H%M%S)\n",
    "  OUTDIR=gs://${BUCKET}/lightning/${ARCH}_trained_gpu\n",
    "  gsutil -m rm -rf $OUTDIR\n",
    "  gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "      --module-name trainer.train_cnn --package-path ${PWD}/ltgpred/trainer --job-dir=$OUTDIR \\\n",
    "      --region=${REGION} --scale-tier CUSTOM --config largemachine.yaml \\\n",
    "      --python-version 3.5 --runtime-version 1.10 \\\n",
    "      -- \\\n",
    "      --train_data_path ${DATADIR}/train-* --eval_data_path ${DATADIR}/eval-* \\\n",
    "      --train_steps 5000 --train_batch_size 256 --num_cores 4 --arch $ARCH \\\n",
    "      --num_eval_records 1024000 --nlayers 5 --dprob 0 --ksize 3 --nfil 10 --learning_rate 0.01 \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Results (Dropout=0)\n",
    "| Architecture | Training time | Validation RMSE | Validation Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| feateng | 23 min | 0.2620 | 0.8233 |\n",
    "| dnn | 62 min | 0.2752 | 0.8272 |\n",
    "| convnet | 24 min | 0.2261 | 0.8462 |\n",
    "| resnet | 63 min | 0.3088 | 0.7142 |\n",
    "\n",
    "### Results (Dropout=0.05)\n",
    "| Architecture | Training time | Validation RMSE | Validation Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| feateng | 20 min | 0.2641 | 0.8258 |\n",
    "| dnn | 58 min | 0.2284 | 0.8412 |\n",
    "| convnet | 23 min | 0.2268 | 0.8459 |\n",
    "| resnet | 80 min | 0.3005 | 0.6887 |\n",
    "\n",
    "\n",
    "Other than for the dnn, dropout doesn't seem to help.  Based on these results, let's train a <b> convnet with no dropout </b>.\n",
    "\n",
    "All the results above are for \n",
    "<pre>\n",
    "--train_steps=5000 --train_batch_size=256 --num_cores=4 --arch=$ARCH \\\n",
    "--num_eval_records=1024000 --nlayers=5 --dprob=... --ksize=3 --nfil=10 --learning_rate=0.01\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam_gpu.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam_gpu.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: complex_model_m_p100\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 2\n",
    "    hyperparameterMetricTag: val_acc\n",
    "    params:\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: nfil\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 30\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: nlayers\n",
    "      type: INTEGER\n",
    "      minValue: 1\n",
    "      maxValue: 5\n",
    "      scaleType: UNIT_LINEAR_SCALE     \n",
    "    - parameterName: train_batch_size # has to be multiple of 128\n",
    "      type: DISCRETE\n",
    "      discreteValues: [128, 256, 512, 1024, 2048, 4096]       \n",
    "\n",
    "#    - parameterName: arch\n",
    "#      type: CATEGORICAL\n",
    "#      categoricalValues: [\"convnet\", \"feateng\", \"resnet\", \"dnn\"]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/lightning/convnet_trained_gpu_hparam\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "JOBNAME=ltgpred_hparam_$(date -u +%y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --module-name=ltgpred.trainer.train_cnn --package-path=${PWD}/ltgpred --job-dir=$OUTDIR \\\n",
    "    --region=${REGION} --scale-tier=CUSTOM --config=hyperparam_gpu.yaml \\\n",
    "    --python-version=3.5 --runtime-version=1.10 \\\n",
    "    -- \\\n",
    "    --train_data_path=${DATADIR}/train-* --eval_data_path=${DATADIR}/eval-* \\\n",
    "    --train_steps=5000 --train_batch_size=256 --num_cores=4 --arch=convnet \\\n",
    "    --num_eval_records=1024000 --nlayers=5 --dprob=0 --ksize=3 --nfil=10 --learning_rate=0.01 --skipexport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter training took 7.5 hours for me, cost 215 ML units (about 110USD list price) and had this as the best set of parameters:\n",
    "<pre>\n",
    "{\n",
    "      \"trialId\": \"2\",\n",
    "      \"hyperparameters\": {\n",
    "        \"nfil\": \"10\",\n",
    "        \"learning_rate\": \"0.02735530997243607\",\n",
    "        \"train_batch_size\": \"1024\",\n",
    "        \"nlayers\": \"3\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"1\",\n",
    "        \"objectiveValue\": 0.846787109375\n",
    "      }\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training lightning prediction model on CMLE using TPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train on the TPU. Because our batch size is 4x, we can train for 4x fewer steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/lightning/cnn_trained_tpu\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "JOBNAME=ltgpred_cnn_$(date -u +%y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --module-name ltgpred.trainer.train_cnn --package-path ${PWD}/ltgpred --job-dir=$OUTDIR \\\n",
    "    --region ${REGION} --scale-tier BASIC_TPU \\\n",
    "    --python-version 3.5 --runtime-version 1.12 \\\n",
    "    -- \\\n",
    "    --train_data_path ${DATADIR}/train* --eval_data_path ${DATADIR}/eval* \\\n",
    "    --train_steps 1250 --train_batch_size 1024 --num_cores 8  --use_tpu \\\n",
    "    --num_eval_records 1024000 --nlayers 5 --dprob 0 --ksize 3 --nfil 10 --learning_rate 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it, training finished with accuracy=0.82 (no change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data, harder problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#DATADIR=gs://$BUCKET/lightning/preproc/tfrecord\n",
    "#DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_1/tfrecord  # also 5-min validity\n",
    "\n",
    "#for ARCH in feateng convnet dnn resnet; do\n",
    "for ARCH in dnn resnet; do\n",
    "  JOBNAME=ltgpred_${ARCH}_$(date -u +%y%m%d_%H%M%S)\n",
    "  OUTDIR=gs://${BUCKET}/lightning/${ARCH}_trained_gpu\n",
    "  gsutil -m rm -rf $OUTDIR\n",
    "  gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "      --module-name ltgpred.trainer.train_cnn --package-path ${PWD}/ltgpred --job-dir=$OUTDIR \\\n",
    "      --region=${REGION} --scale-tier CUSTOM --config largemachine.yaml \\\n",
    "      --python-version 3.5 --runtime-version 1.12 \\\n",
    "      -- \\\n",
    "      --train_data_path ${DATADIR}/train-* --eval_data_path ${DATADIR}/eval-* \\\n",
    "      --train_steps 5000 --train_batch_size 256 --num_cores 4 --arch $ARCH \\\n",
    "      --num_eval_records 1024000 --nlayers 5 --dprob 0 --ksize 3 --nfil 10 --learning_rate 0.01 \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Architecture | Training time | Validation RMSE | Validation Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| feateng | 26 min | 0.2986 | 0.7901 |\n",
    "| dnn | 40 min | 0.2995 | 0.7916 |\n",
    "| convnet | 28 min | 0.2735 | 0.8141 |\n",
    "| resnet | 68 min | 0.5135 | 0.4852 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \\\"License\\\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
